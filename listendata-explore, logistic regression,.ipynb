{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import required libraries\n",
    "import pandas as pd\n",
    "import statsmodels.api as sm\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read data from web\n",
    "df = pd.read_csv(\"https://stats.idre.ucla.edu/stat/data/binary.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>admit</th>\n",
       "      <th>gre</th>\n",
       "      <th>gpa</th>\n",
       "      <th>rank</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>380</td>\n",
       "      <td>3.61</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>660</td>\n",
       "      <td>3.67</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>800</td>\n",
       "      <td>4.00</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>640</td>\n",
       "      <td>3.19</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>520</td>\n",
       "      <td>2.93</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   admit  gre   gpa  rank\n",
       "0      0  380  3.61     3\n",
       "1      1  660  3.67     3\n",
       "2      1  800  4.00     1\n",
       "3      1  640  3.19     4\n",
       "4      0  520  2.93     4"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(400, 4)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# See no. of rows and columns\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>admit</th>\n",
       "      <th>gre</th>\n",
       "      <th>gpa</th>\n",
       "      <th>rank</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>380</td>\n",
       "      <td>3.61</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>660</td>\n",
       "      <td>3.67</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>800</td>\n",
       "      <td>4.00</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>640</td>\n",
       "      <td>3.19</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1</td>\n",
       "      <td>760</td>\n",
       "      <td>3.00</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0</td>\n",
       "      <td>400</td>\n",
       "      <td>3.08</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1</td>\n",
       "      <td>540</td>\n",
       "      <td>3.39</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0</td>\n",
       "      <td>700</td>\n",
       "      <td>3.92</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0</td>\n",
       "      <td>800</td>\n",
       "      <td>4.00</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0</td>\n",
       "      <td>440</td>\n",
       "      <td>3.22</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>1</td>\n",
       "      <td>760</td>\n",
       "      <td>4.00</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0</td>\n",
       "      <td>700</td>\n",
       "      <td>3.08</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>1</td>\n",
       "      <td>700</td>\n",
       "      <td>4.00</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0</td>\n",
       "      <td>480</td>\n",
       "      <td>3.44</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0</td>\n",
       "      <td>780</td>\n",
       "      <td>3.87</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0</td>\n",
       "      <td>800</td>\n",
       "      <td>3.75</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>1</td>\n",
       "      <td>540</td>\n",
       "      <td>3.81</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0</td>\n",
       "      <td>500</td>\n",
       "      <td>3.17</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>1</td>\n",
       "      <td>660</td>\n",
       "      <td>3.63</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0</td>\n",
       "      <td>680</td>\n",
       "      <td>3.19</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>1</td>\n",
       "      <td>760</td>\n",
       "      <td>3.35</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>1</td>\n",
       "      <td>800</td>\n",
       "      <td>3.66</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>1</td>\n",
       "      <td>620</td>\n",
       "      <td>3.61</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>1</td>\n",
       "      <td>520</td>\n",
       "      <td>3.74</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>1</td>\n",
       "      <td>780</td>\n",
       "      <td>3.22</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>0</td>\n",
       "      <td>520</td>\n",
       "      <td>3.29</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>0</td>\n",
       "      <td>540</td>\n",
       "      <td>3.78</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>0</td>\n",
       "      <td>760</td>\n",
       "      <td>3.35</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>0</td>\n",
       "      <td>600</td>\n",
       "      <td>3.40</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>1</td>\n",
       "      <td>800</td>\n",
       "      <td>4.00</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>364</th>\n",
       "      <td>1</td>\n",
       "      <td>560</td>\n",
       "      <td>3.36</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>367</th>\n",
       "      <td>0</td>\n",
       "      <td>620</td>\n",
       "      <td>3.63</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>368</th>\n",
       "      <td>0</td>\n",
       "      <td>580</td>\n",
       "      <td>4.00</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>369</th>\n",
       "      <td>0</td>\n",
       "      <td>800</td>\n",
       "      <td>3.89</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>370</th>\n",
       "      <td>1</td>\n",
       "      <td>540</td>\n",
       "      <td>3.77</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>371</th>\n",
       "      <td>1</td>\n",
       "      <td>680</td>\n",
       "      <td>3.76</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>373</th>\n",
       "      <td>1</td>\n",
       "      <td>620</td>\n",
       "      <td>3.37</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>374</th>\n",
       "      <td>0</td>\n",
       "      <td>560</td>\n",
       "      <td>3.78</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>375</th>\n",
       "      <td>0</td>\n",
       "      <td>560</td>\n",
       "      <td>3.49</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>376</th>\n",
       "      <td>0</td>\n",
       "      <td>620</td>\n",
       "      <td>3.63</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>377</th>\n",
       "      <td>1</td>\n",
       "      <td>800</td>\n",
       "      <td>4.00</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>378</th>\n",
       "      <td>0</td>\n",
       "      <td>640</td>\n",
       "      <td>3.12</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>380</th>\n",
       "      <td>0</td>\n",
       "      <td>700</td>\n",
       "      <td>3.65</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>381</th>\n",
       "      <td>1</td>\n",
       "      <td>540</td>\n",
       "      <td>3.49</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>382</th>\n",
       "      <td>0</td>\n",
       "      <td>540</td>\n",
       "      <td>3.51</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>383</th>\n",
       "      <td>0</td>\n",
       "      <td>660</td>\n",
       "      <td>4.00</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>385</th>\n",
       "      <td>0</td>\n",
       "      <td>420</td>\n",
       "      <td>3.02</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>386</th>\n",
       "      <td>1</td>\n",
       "      <td>740</td>\n",
       "      <td>3.86</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>387</th>\n",
       "      <td>0</td>\n",
       "      <td>580</td>\n",
       "      <td>3.36</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>388</th>\n",
       "      <td>0</td>\n",
       "      <td>640</td>\n",
       "      <td>3.17</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>389</th>\n",
       "      <td>0</td>\n",
       "      <td>640</td>\n",
       "      <td>3.51</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>390</th>\n",
       "      <td>1</td>\n",
       "      <td>800</td>\n",
       "      <td>3.05</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>391</th>\n",
       "      <td>1</td>\n",
       "      <td>660</td>\n",
       "      <td>3.88</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>392</th>\n",
       "      <td>1</td>\n",
       "      <td>600</td>\n",
       "      <td>3.38</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>393</th>\n",
       "      <td>1</td>\n",
       "      <td>620</td>\n",
       "      <td>3.75</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>394</th>\n",
       "      <td>1</td>\n",
       "      <td>460</td>\n",
       "      <td>3.99</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>395</th>\n",
       "      <td>0</td>\n",
       "      <td>620</td>\n",
       "      <td>4.00</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>396</th>\n",
       "      <td>0</td>\n",
       "      <td>560</td>\n",
       "      <td>3.04</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>398</th>\n",
       "      <td>0</td>\n",
       "      <td>700</td>\n",
       "      <td>3.65</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>399</th>\n",
       "      <td>0</td>\n",
       "      <td>600</td>\n",
       "      <td>3.89</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>333 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     admit  gre   gpa  rank\n",
       "0        0  380  3.61     3\n",
       "1        1  660  3.67     3\n",
       "2        1  800  4.00     1\n",
       "3        1  640  3.19     4\n",
       "5        1  760  3.00     2\n",
       "7        0  400  3.08     2\n",
       "8        1  540  3.39     3\n",
       "9        0  700  3.92     2\n",
       "10       0  800  4.00     4\n",
       "11       0  440  3.22     1\n",
       "12       1  760  4.00     1\n",
       "13       0  700  3.08     2\n",
       "14       1  700  4.00     1\n",
       "15       0  480  3.44     3\n",
       "16       0  780  3.87     4\n",
       "18       0  800  3.75     2\n",
       "19       1  540  3.81     1\n",
       "20       0  500  3.17     3\n",
       "21       1  660  3.63     2\n",
       "23       0  680  3.19     4\n",
       "24       1  760  3.35     2\n",
       "25       1  800  3.66     1\n",
       "26       1  620  3.61     1\n",
       "27       1  520  3.74     4\n",
       "28       1  780  3.22     2\n",
       "29       0  520  3.29     1\n",
       "30       0  540  3.78     4\n",
       "31       0  760  3.35     3\n",
       "32       0  600  3.40     3\n",
       "33       1  800  4.00     3\n",
       "..     ...  ...   ...   ...\n",
       "364      1  560  3.36     1\n",
       "367      0  620  3.63     3\n",
       "368      0  580  4.00     1\n",
       "369      0  800  3.89     2\n",
       "370      1  540  3.77     2\n",
       "371      1  680  3.76     3\n",
       "373      1  620  3.37     1\n",
       "374      0  560  3.78     2\n",
       "375      0  560  3.49     4\n",
       "376      0  620  3.63     2\n",
       "377      1  800  4.00     2\n",
       "378      0  640  3.12     3\n",
       "380      0  700  3.65     2\n",
       "381      1  540  3.49     2\n",
       "382      0  540  3.51     2\n",
       "383      0  660  4.00     1\n",
       "385      0  420  3.02     1\n",
       "386      1  740  3.86     2\n",
       "387      0  580  3.36     2\n",
       "388      0  640  3.17     2\n",
       "389      0  640  3.51     2\n",
       "390      1  800  3.05     2\n",
       "391      1  660  3.88     2\n",
       "392      1  600  3.38     3\n",
       "393      1  620  3.75     2\n",
       "394      1  460  3.99     3\n",
       "395      0  620  4.00     2\n",
       "396      0  560  3.04     3\n",
       "398      0  700  3.65     2\n",
       "399      0  600  3.89     3\n",
       "\n",
       "[333 rows x 4 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#select variables\n",
    "df[['admit', 'gre']]\n",
    "#filter data\n",
    "df.query('gpa >= 3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 400 entries, 0 to 399\n",
      "Data columns (total 4 columns):\n",
      "admit    400 non-null int64\n",
      "gre      400 non-null int64\n",
      "gpa      400 non-null float64\n",
      "rank     400 non-null int64\n",
      "dtypes: float64(1), int64(3)\n",
      "memory usage: 12.6 KB\n"
     ]
    }
   ],
   "source": [
    "#structure and data type for dataframe\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>admit</th>\n",
       "      <th>gre</th>\n",
       "      <th>gpa</th>\n",
       "      <th>rank</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>400.000000</td>\n",
       "      <td>400.000000</td>\n",
       "      <td>400.000000</td>\n",
       "      <td>400.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.317500</td>\n",
       "      <td>587.700000</td>\n",
       "      <td>3.389900</td>\n",
       "      <td>2.48500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.466087</td>\n",
       "      <td>115.516536</td>\n",
       "      <td>0.380567</td>\n",
       "      <td>0.94446</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>220.000000</td>\n",
       "      <td>2.260000</td>\n",
       "      <td>1.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>520.000000</td>\n",
       "      <td>3.130000</td>\n",
       "      <td>2.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>580.000000</td>\n",
       "      <td>3.395000</td>\n",
       "      <td>2.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>660.000000</td>\n",
       "      <td>3.670000</td>\n",
       "      <td>3.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>800.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.00000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            admit         gre         gpa       rank\n",
       "count  400.000000  400.000000  400.000000  400.00000\n",
       "mean     0.317500  587.700000    3.389900    2.48500\n",
       "std      0.466087  115.516536    0.380567    0.94446\n",
       "min      0.000000  220.000000    2.260000    1.00000\n",
       "25%      0.000000  520.000000    3.130000    2.00000\n",
       "50%      0.000000  580.000000    3.395000    2.00000\n",
       "75%      1.000000  660.000000    3.670000    3.00000\n",
       "max      1.000000  800.000000    4.000000    4.00000"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Summarize dataframe\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      False\n",
       "1      False\n",
       "2      False\n",
       "3      False\n",
       "4      False\n",
       "5      False\n",
       "6      False\n",
       "7      False\n",
       "8      False\n",
       "9      False\n",
       "10     False\n",
       "11     False\n",
       "12     False\n",
       "13     False\n",
       "14     False\n",
       "15     False\n",
       "16     False\n",
       "17     False\n",
       "18     False\n",
       "19     False\n",
       "20     False\n",
       "21     False\n",
       "22     False\n",
       "23     False\n",
       "24     False\n",
       "25     False\n",
       "26     False\n",
       "27     False\n",
       "28     False\n",
       "29     False\n",
       "       ...  \n",
       "370    False\n",
       "371    False\n",
       "372    False\n",
       "373    False\n",
       "374    False\n",
       "375    False\n",
       "376    False\n",
       "377    False\n",
       "378    False\n",
       "379    False\n",
       "380    False\n",
       "381    False\n",
       "382    False\n",
       "383    False\n",
       "384    False\n",
       "385    False\n",
       "386    False\n",
       "387    False\n",
       "388    False\n",
       "389    False\n",
       "390    False\n",
       "391    False\n",
       "392    False\n",
       "393    False\n",
       "394    False\n",
       "395    False\n",
       "396    False\n",
       "397    False\n",
       "398    False\n",
       "399    False\n",
       "Name: gpa, Length: 400, dtype: bool"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#check isnull value(missing)\n",
    "pd.isnull(df.gpa)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rename rank column\n",
    "df = df.rename(columns={'rank': 'position'}) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[<matplotlib.axes._subplots.AxesSubplot object at 0x000001F7C5248D30>,\n",
       "        <matplotlib.axes._subplots.AxesSubplot object at 0x000001F7C5291978>],\n",
       "       [<matplotlib.axes._subplots.AxesSubplot object at 0x000001F7C52C0BE0>,\n",
       "        <matplotlib.axes._subplots.AxesSubplot object at 0x000001F7C4F2EE10>]],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 4 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plot all of the columns\n",
    "df.hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1     61\n",
       "4     67\n",
       "3    121\n",
       "2    151\n",
       "Name: position, dtype: int64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# frequency distribution of categorical variable\n",
    "df.position.value_counts(ascending=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>position</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>admit</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>28</td>\n",
       "      <td>97</td>\n",
       "      <td>93</td>\n",
       "      <td>55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>33</td>\n",
       "      <td>54</td>\n",
       "      <td>28</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "position   1   2   3   4\n",
       "admit                   \n",
       "0         28  97  93  55\n",
       "1         33  54  28  12"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# crosstab for row,column\n",
    "pd.crosstab(df['admit'], df['position'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "admit 0\n",
      "gre 0\n",
      "gpa 0\n",
      "position 0\n"
     ]
    }
   ],
   "source": [
    "#checking missing data by looping\n",
    "\n",
    "for i in list(df.columns) :\n",
    "    k = sum(pd.isnull(df[i]))\n",
    "    print(i, k)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "logistic regression\n",
    "logistic regression model returns probability of target variable where is categorical variable\n",
    "\n",
    "Logistic Regression is a special type of regression where target variable is categorical in nature and independent variables be discrete or continuous. In this post, we will demonstrate only binary logistic regression which takes only binary values in target variable. Unlike linear regression, logistic regression model returns probability of target variable.It assumes binomial distribution of dependent variable. In other words, it belongs to binomial family.\n",
    "\n",
    "In python, we can write R-style model formula y ~ x1 + x2 + x3 using  patsy and statsmodels libraries. In the formula, we need to define variable 'position' as a categorical variable by mentioning it inside capital C(). You can also define reference category using reference= option."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#logistic regression\n",
    "#Reference Category\n",
    "from patsy import dmatrices, Treatment\n",
    "y, X = dmatrices('admit ~ gre + gpa + C(position, Treatment(reference=4))', df, return_type = 'dataframe')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Split Data into two parts\n",
    "\n",
    "#80% of data goes to training dataset which is used for building model and 20% goes to test dataset which would be used for validating the model\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 0.571367\n",
      "         Iterations 6\n"
     ]
    }
   ],
   "source": [
    "#Fit Logit model\n",
    "logit = sm.Logit(y_train, X_train)\n",
    "result = logit.fit()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>Logit Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>       <td>admit</td>      <th>  No. Observations:  </th>  <td>   320</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>               <td>Logit</td>      <th>  Df Residuals:      </th>  <td>   314</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>               <td>MLE</td>       <th>  Df Model:          </th>  <td>     5</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>          <td>Thu, 28 Mar 2019</td> <th>  Pseudo R-squ.:     </th>  <td>0.08716</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>              <td>23:28:55</td>     <th>  Log-Likelihood:    </th> <td> -182.84</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>converged:</th>           <td>True</td>       <th>  LL-Null:           </th> <td> -200.30</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th> </th>                      <td> </td>        <th>  LLR p-value:       </th> <td>1.564e-06</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "                      <td></td>                        <th>coef</th>     <th>std err</th>      <th>z</th>      <th>P>|z|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Intercept</th>                                <td>   -5.6170</td> <td>    1.284</td> <td>   -4.376</td> <td> 0.000</td> <td>   -8.133</td> <td>   -3.101</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>C(position, Treatment(reference=4))[T.1]</th> <td>    1.8081</td> <td>    0.487</td> <td>    3.713</td> <td> 0.000</td> <td>    0.854</td> <td>    2.762</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>C(position, Treatment(reference=4))[T.2]</th> <td>    1.1054</td> <td>    0.432</td> <td>    2.557</td> <td> 0.011</td> <td>    0.258</td> <td>    1.952</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>C(position, Treatment(reference=4))[T.3]</th> <td>    0.3775</td> <td>    0.463</td> <td>    0.815</td> <td> 0.415</td> <td>   -0.530</td> <td>    1.285</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>gre</th>                                      <td>    0.0018</td> <td>    0.001</td> <td>    1.456</td> <td> 0.145</td> <td>   -0.001</td> <td>    0.004</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>gpa</th>                                      <td>    0.8518</td> <td>    0.368</td> <td>    2.312</td> <td> 0.021</td> <td>    0.130</td> <td>    1.574</td>\n",
       "</tr>\n",
       "</table>"
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                           Logit Regression Results                           \n",
       "==============================================================================\n",
       "Dep. Variable:                  admit   No. Observations:                  320\n",
       "Model:                          Logit   Df Residuals:                      314\n",
       "Method:                           MLE   Df Model:                            5\n",
       "Date:                Thu, 28 Mar 2019   Pseudo R-squ.:                 0.08716\n",
       "Time:                        23:28:55   Log-Likelihood:                -182.84\n",
       "converged:                       True   LL-Null:                       -200.30\n",
       "                                        LLR p-value:                 1.564e-06\n",
       "============================================================================================================\n",
       "                                               coef    std err          z      P>|z|      [0.025      0.975]\n",
       "------------------------------------------------------------------------------------------------------------\n",
       "Intercept                                   -5.6170      1.284     -4.376      0.000      -8.133      -3.101\n",
       "C(position, Treatment(reference=4))[T.1]     1.8081      0.487      3.713      0.000       0.854       2.762\n",
       "C(position, Treatment(reference=4))[T.2]     1.1054      0.432      2.557      0.011       0.258       1.952\n",
       "C(position, Treatment(reference=4))[T.3]     0.3775      0.463      0.815      0.415      -0.530       1.285\n",
       "gre                                          0.0018      0.001      1.456      0.145      -0.001       0.004\n",
       "gpa                                          0.8518      0.368      2.312      0.021       0.130       1.574\n",
       "============================================================================================================\n",
       "\"\"\""
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Summary of Logistic regression model\n",
    "result.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Intercept                                  -5.616988\n",
       "C(position, Treatment(reference=4))[T.1]    1.808055\n",
       "C(position, Treatment(reference=4))[T.2]    1.105371\n",
       "C(position, Treatment(reference=4))[T.3]    0.377535\n",
       "gre                                         0.001788\n",
       "gpa                                         0.851847\n",
       "dtype: float64"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# formula of coefficient of each variables\n",
    "result.params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[202.,  16.],\n",
       "       [ 75.,  27.]])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Confusion Matrix\n",
    "result.pred_table()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Odd ratio is exponential value of parameter estimates.\n",
    "#Odd Ratio\n",
    "np.exp(result.params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "#prediction on test data\n",
    "y_pred = result.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'roc_curve' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-33-acbfa0cd500e>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m#Calculate Area under Curve (ROC)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;31m# AUC on test data\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mfalse_positive_rate\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrue_positive_rate\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mthresholds\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mroc_curve\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[0mauc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfalse_positive_rate\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrue_positive_rate\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'roc_curve' is not defined"
     ]
    }
   ],
   "source": [
    "#Calculate Area under Curve (ROC)\n",
    "# AUC on test data\n",
    "false_positive_rate, true_positive_rate, thresholds = roc_curve(y_test, y_pred)\n",
    "auc(false_positive_rate, true_positive_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'accuracy_score' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-34-3efcd826fd9f>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0maccuracy_score\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m \u001b[1;36m1\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mp\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m0.5\u001b[0m \u001b[1;32melse\u001b[0m \u001b[1;36m0\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mp\u001b[0m \u001b[1;32min\u001b[0m \u001b[0my_pred\u001b[0m \u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'accuracy_score' is not defined"
     ]
    }
   ],
   "source": [
    "#Calculate Accuracy Score\n",
    "accuracy_score([ 1 if p > 0.5 else 0 for p in y_pred ], y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Decision Tree Model\n",
    "\n",
    "Decision trees can have a target variable continuous or categorical. When it is continuous, it is called regression tree. And when it is categorical, it is called classification tree. It selects a variable at each step that best splits the set of values. There are several algorithms to find best split. Some of them are Gini, Entropy, C4.5, Chi-Square. There are several advantages of decision tree. It is simple to use and easy to understand. It requires a very few data preparation steps. It can handle mixed data - both categorical and continuous variables. In terms of speed, it is a very fast algorithm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'roc_curve' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-35-5c981c29e9d4>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     16\u001b[0m \u001b[1;31m#AUC\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 17\u001b[1;33m \u001b[0mfalse_positive_rate\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrue_positive_rate\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mthresholds\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mroc_curve\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpredictions_tree\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     18\u001b[0m \u001b[0mauc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfalse_positive_rate\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrue_positive_rate\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'roc_curve' is not defined"
     ]
    }
   ],
   "source": [
    "#Decision Tree Model\n",
    "#Drop Intercept from predictors for tree algorithms\n",
    "X_train = X_train.drop(['Intercept'], axis = 1)\n",
    "X_test = X_test.drop(['Intercept'], axis = 1)\n",
    "\n",
    "#Decision Tree\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "model_tree = DecisionTreeClassifier(max_depth=7)\n",
    "\n",
    "#Fit the model:\n",
    "model_tree.fit(X_train,y_train)\n",
    "\n",
    "#Make predictions on test set\n",
    "predictions_tree = model_tree.predict_proba(X_test)\n",
    "  \n",
    "#AUC\n",
    "false_positive_rate, true_positive_rate, thresholds = roc_curve(y_test, predictions_tree[:,1])\n",
    "auc(false_positive_rate, true_positive_rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Random Forest Model\n",
    "\n",
    "Decision Tree has limitation of overfitting which implies it does not generalize pattern. It is very sensitive to a small change in training data. To overcome this problem, random forest comes into picture. It grows a large number of trees on randomised data. It selects random number of variables to grow each tree. It is more robust algorithm than decision tree. It is one of the most popular machine learning algorithm. It is commonly used in data science competitions. It is always ranked in top 5 algorithms. It has become a part of every data science toolkit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'roc_curve' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-36-1dbd15fb11c8>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[1;31m#AUC\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 13\u001b[1;33m \u001b[0mfalse_positive_rate\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrue_positive_rate\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mthresholds\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mroc_curve\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpredictions_rf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     14\u001b[0m \u001b[0mauc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfalse_positive_rate\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrue_positive_rate\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'roc_curve' is not defined"
     ]
    }
   ],
   "source": [
    "#Random Forest\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "model_rf = RandomForestClassifier(n_estimators=100, max_depth=7)\n",
    "\n",
    "#Fit the model:\n",
    "target = y_train['admit']\n",
    "model_rf.fit(X_train,target)\n",
    "\n",
    "#Make predictions on test set\n",
    "predictions_rf = model_rf.predict_proba(X_test)\n",
    "\n",
    "#AUC\n",
    "false_positive_rate, true_positive_rate, thresholds = roc_curve(y_test, predictions_rf[:,1])\n",
    "auc(false_positive_rate, true_positive_rate)\n",
    "\n",
    "#Variable Importance\n",
    "importances = pd.Series(model_rf.feature_importances_, index=X_train.columns).sort_values(ascending=False)\n",
    "print(importances)\n",
    "importances.plot.bar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Grid Search - Hyper Parameters Tuning\n",
    "\n",
    "The sklearn library makes hyper-parameters tuning very easy. It is a strategy to select the best parameters for an algorithm. In scikit-learn they are passed as arguments to the constructor of the estimator classes. For example, max_features in randomforest. alpha for lasso.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\cheungpakyinpatrick\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:841: DeprecationWarning: The default of the `iid` parameter will change from True to False in version 0.22 and will be removed in 0.24. This will change numeric results when test-set sizes are unequal.\n",
      "  DeprecationWarning)\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'GridSearchCV' object has no attribute 'grid_scores_'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-38-fae8b196e120>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[1;31m#Parameters with Scores\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 14\u001b[1;33m \u001b[0mCV_rfc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgrid_scores_\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     15\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     16\u001b[0m \u001b[1;31m#Best Parameters\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'GridSearchCV' object has no attribute 'grid_scores_'"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "rf = RandomForestClassifier()\n",
    "target = y_train['admit']\n",
    "\n",
    "param_grid = { \n",
    "    'n_estimators': [100, 200, 300],\n",
    "    'max_features': ['sqrt', 3, 4]\n",
    "}\n",
    "\n",
    "CV_rfc = GridSearchCV(estimator=rf , param_grid=param_grid, cv= 5, scoring='roc_auc')\n",
    "CV_rfc.fit(X_train,target)\n",
    "\n",
    "#Parameters with Scores\n",
    "CV_rfc.grid_scores_\n",
    "\n",
    "#Best Parameters\n",
    "CV_rfc.best_params_\n",
    "CV_rfc.best_estimator_\n",
    "\n",
    "#Make predictions on test set\n",
    "predictions_rf = CV_rfc.predict_proba(X_test)\n",
    "\n",
    "#AUC\n",
    "false_positive_rate, true_positive_rate, thresholds = roc_curve(y_test, predictions_rf[:,1])\n",
    "auc(false_positive_rate, true_positive_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\cheungpakyinpatrick\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\cheungpakyinpatrick\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\cheungpakyinpatrick\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\cheungpakyinpatrick\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\cheungpakyinpatrick\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\cheungpakyinpatrick\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\cheungpakyinpatrick\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\cheungpakyinpatrick\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\cheungpakyinpatrick\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\cheungpakyinpatrick\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\cheungpakyinpatrick\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\cheungpakyinpatrick\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\cheungpakyinpatrick\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\cheungpakyinpatrick\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\cheungpakyinpatrick\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\cheungpakyinpatrick\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\cheungpakyinpatrick\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\cheungpakyinpatrick\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\cheungpakyinpatrick\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\cheungpakyinpatrick\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0.81318681, 0.59340659, 0.75274725, 0.80911681, 0.73076923,\n",
       "       0.63247863, 0.62108262, 0.42901235, 0.67283951, 0.57098765])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Cross Validation\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import cross_val_predict,cross_val_score\n",
    "target = y['admit']\n",
    "prediction_logit = cross_val_predict(LogisticRegression(), X, target, cv=10, method='predict_proba')\n",
    "#AUC\n",
    "cross_val_score(LogisticRegression(fit_intercept = False), X, target, cv=10, scoring='roc_auc')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "sklearn requires all categorical variables in numeric form. Hence, we need to convert all character/categorical variables to be numericm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "def ConverttoNumeric(df):\n",
    "    cols = list(df.select_dtypes(include=['category','object']))\n",
    "    le = LabelEncoder()\n",
    "    for i in cols:\n",
    "        try:\n",
    "            df[i] = le.fit_transform(df[i])\n",
    "        except:\n",
    "            print('Error in Variable :'+i)\n",
    "    return df\n",
    "\n",
    "ConverttoNumeric(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'productcode'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\core\\indexes\\base.py\u001b[0m in \u001b[0;36mget_loc\u001b[1;34m(self, key, method, tolerance)\u001b[0m\n\u001b[0;32m   3077\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3078\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3079\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'productcode'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-40-b2a5403b0593>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mproductcode_dummy\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_dummies\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"productcode\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mdf2\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconcat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mdf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mproductcode_dummy\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   2686\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_getitem_multilevel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2687\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2688\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_getitem_column\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2689\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2690\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_getitem_column\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36m_getitem_column\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   2693\u001b[0m         \u001b[1;31m# get column\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2694\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mis_unique\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2695\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_item_cache\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2696\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2697\u001b[0m         \u001b[1;31m# duplicate columns & possible reduce dimensionality\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\core\\generic.py\u001b[0m in \u001b[0;36m_get_item_cache\u001b[1;34m(self, item)\u001b[0m\n\u001b[0;32m   2487\u001b[0m         \u001b[0mres\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcache\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2488\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mres\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2489\u001b[1;33m             \u001b[0mvalues\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_data\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2490\u001b[0m             \u001b[0mres\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_box_item_values\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalues\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2491\u001b[0m             \u001b[0mcache\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mitem\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mres\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\core\\internals.py\u001b[0m in \u001b[0;36mget\u001b[1;34m(self, item, fastpath)\u001b[0m\n\u001b[0;32m   4113\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4114\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0misna\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 4115\u001b[1;33m                 \u001b[0mloc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   4116\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4117\u001b[0m                 \u001b[0mindexer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0misna\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\core\\indexes\\base.py\u001b[0m in \u001b[0;36mget_loc\u001b[1;34m(self, key, method, tolerance)\u001b[0m\n\u001b[0;32m   3078\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3079\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3080\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_maybe_cast_indexer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3081\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3082\u001b[0m         \u001b[0mindexer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_indexer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmethod\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtolerance\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtolerance\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'productcode'"
     ]
    }
   ],
   "source": [
    "productcode_dummy = pd.get_dummies(df[\"productcode\"])\n",
    "df2 = pd.concat([df, productcode_dummy], axis=1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
